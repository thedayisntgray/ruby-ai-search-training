{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cac0eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "require 'httparty'\n",
    "require 'numo/narray'\n",
    "require 'openai'\n",
    "require 'faiss'\n",
    "require 'dotenv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444bf29c-08ef-4c69-b9e1-e451d3f97a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dotenv.load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1265846b",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = HTTParty.get('https://raw.githubusercontent.com/run-llama/llama_index/main/docs/docs/examples/data/paul_graham/paul_graham_essay.txt')\n",
    "text = response.body\n",
    "\n",
    "File.open('essay.txt', 'w') { |file| file.write(text) }\n",
    "\n",
    "text.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bca444",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 2048\n",
    "chunks = text.chars.each_slice(chunk_size).map(&:join)\n",
    "chunks.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf3ce5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI::Client.new(\n",
    " access_token: ENV['OPENAI_API_KEY'],\n",
    " request_options: {\n",
    "   headers: {\n",
    "     'Authorization': \"Bearer #{ENV['OPENAI_API_KEY']}\"\n",
    "   }\n",
    " }\n",
    ")\n",
    "\n",
    "def get_text_embedding(client, input)\n",
    "  response = client.embeddings(\n",
    "    parameters: {\n",
    "      model: 'text-embedding-3-small',\n",
    "      input: input\n",
    "    }\n",
    "  )\n",
    "  response.dig('data', 0, 'embedding')\n",
    "end\n",
    "\n",
    "text_embeddings = chunks.map { |chunk| get_text_embedding(client, chunk) }\n",
    "text_embeddings = Numo::DFloat[*text_embeddings]\n",
    "text_embeddings.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2631135",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = text_embeddings.shape[1]\n",
    "index = Faiss::IndexFlatL2.new(d)\n",
    "index.add(text_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bc973f",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What were the two main things the author worked on before college?\"\n",
    "question_embedding = get_text_embedding(client, question)\n",
    "question_embeddings = question_embedding\n",
    "# question_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a7a55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "distances, indices = index.search([question_embeddings], 2)\n",
    "index_array = indices.to_a[0]\n",
    "retrieved_chunks = index_array.map { |i| chunks[i] }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbe5cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = <<-PROMPT\n",
    "Context information is below.\n",
    "---------------------\n",
    "#{retrieved_chunks.join(\"\\n---------------------\\n\")}\n",
    "---------------------\n",
    "Given the context information and not prior knowledge, answer the query.\n",
    "Query: #{question}\n",
    "Answer:\n",
    "PROMPT\n",
    "\n",
    "def run_completion(client, user_message, model: 'gpt-3.5-turbo')\n",
    "  response = client.chat(\n",
    "    parameters: {\n",
    "      model: model,\n",
    "      messages: [{ role: 'user', content: user_message }],\n",
    "      temperature: 0.0\n",
    "    }\n",
    "  )\n",
    "  response.dig('choices', 0, 'message', 'content')\n",
    "end\n",
    "\n",
    "puts run_completion(client, prompt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Ruby 3.1.3",
   "language": "ruby",
   "name": "ruby"
  },
  "language_info": {
   "file_extension": ".rb",
   "mimetype": "application/x-ruby",
   "name": "ruby",
   "version": "3.1.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
