{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9485b711-276b-4535-a522-03f9493a4f28",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Lab 2 - Basic sentence transformer inference and similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a60735-6aaa-4f08-9e5d-905cf8246665",
   "metadata": {},
   "outputs": [],
   "source": [
    "system(\"rm embeddings.cache\")\n",
    "system(\"sh prepare_embeddings_cache.sh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7fd151-4d82-4b0b-ad3b-b3b4e6bc829d",
   "metadata": {},
   "outputs": [],
   "source": [
    "require 'transformers-rb'\n",
    "model = Transformers.pipeline(\"embedding\", \"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d327262-5875-4cd4-ae66-235cc4a9f54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example from https://sbert.net\n",
    "sentences = [\n",
    "    'This framework generates embeddings for each input sentence',\n",
    "    'Sentences are passed as a list of string.',\n",
    "    'The quick brown fox jumps over the lazy dog.'\n",
    "]\n",
    "\n",
    "sentence_embeddings = model.(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5276c6-5a59-4182-be56-701f26f18ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate and print the similarity between all three example sentence embeddings\n",
    "cos = Torch::NN::CosineSimilarity.new(dim: 1, eps: 1e-6)\n",
    "\n",
    "# Convert arrays to tensors and reshape them\n",
    "tensor0 = Torch.tensor(sentence_embeddings[0]).unsqueeze(0)\n",
    "tensor1 = Torch.tensor(sentence_embeddings[1]).unsqueeze(0)\n",
    "tensor2 = Torch.tensor(sentence_embeddings[2]).unsqueeze(0)\n",
    "\n",
    "# Calculate cosine similarity\n",
    "similarity01 = cos.call(tensor0, tensor1)\n",
    "similarity02 = cos.call(tensor0, tensor2)\n",
    "similarity12 = cos.call(tensor1, tensor2)\n",
    "\n",
    "puts \"#{similarity01} : '#{sentences[0]}' :: '#{sentences[1]}'\"\n",
    "puts \"#{similarity02} : '#{sentences[0]}' :: '#{sentences[2]}'\"\n",
    "puts \"#{similarity12} : '#{sentences[1]}' :: '#{sentences[2]}'\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181d5fb7-eecc-4797-8e2c-bf3ca5dd840d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Inference of a small dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b77933b-dc82-4f77-9260-e6b057380531",
   "metadata": {},
   "outputs": [],
   "source": [
    "puts `free -h`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2ce856-ac25-44e8-9254-c797cfe65f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the model card here: https://huggingface.co/intfloat/e5-small-v2\n",
    "model = Transformers.pipeline(\"embedding\", \"intfloat/e5-small-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27bda53-5b31-459c-a37a-edcfd4c5fa4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should result in about 100MB less RAM available\n",
    "puts `free -h`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d2187d-1914-41cf-a5cd-37fdcef20eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(model, texts, prefix: \"passage: \")\n",
    "  puts texts\n",
    "  texts = [texts] unless texts.is_a?(Array)\n",
    "  total = texts.length\n",
    "  embeddings = []\n",
    "  \n",
    "  texts.each_with_index do |text, i|\n",
    "    prefixed_text = \"#{prefix}#{text}\"\n",
    "    embedding = model.(prefixed_text)\n",
    "    embeddings << embedding\n",
    "    \n",
    "    percent = ((i + 1).to_f / total * 100).to_i\n",
    "    print \"\\rProcessing embeddings: #{percent}% (#{i + 1}/#{total})\"\n",
    "  end\n",
    "  \n",
    "  print \"\\nDone!\\n\"\n",
    "  embeddings\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3b1678-df09-49a8-b17c-c53ad1577962",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_e5 = get_embeddings(model,[\"Hello world\"])\n",
    "\n",
    "#stand in for test_e5.shape. Alternatively use nmatrix or some other library\n",
    "puts \"First dimension: #{test_e5.length}\"\n",
    "puts \"Second dimension: #{test_e5[0].length}\" if test_e5[0].is_a?(Array)\n",
    "\n",
    "puts test_e5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7356799-7071-4076-a8e7-d588aace78a6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### We use part of the CC_News dataset from Huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8fb43c-b271-4d33-814f-c1143f4eb485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load 50000 examples of the 'cc_news' dataset from Hugging Face\n",
    "require 'polars-df'\n",
    "df = Polars.read_parquet('hf://datasets/vblagoje/cc_news/plain_text/train-*.parquet',n_rows:50_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a076208a-28af-40cd-89b9-f00376e7b023",
   "metadata": {},
   "outputs": [],
   "source": [
    "puts df['title']\n",
    "title_array = df['title'].to_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfebb982-30a2-44f6-b66a-3673f3f1f125",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_embedding(embedding, file)\n",
    "  File.open(file, 'ab') do |f| \n",
    "    Marshal.dump(embedding, f)\n",
    "  end\n",
    "end\n",
    "\n",
    "def each_embedding(file)\n",
    "  return enum_for(:each_embedding, file) unless block_given?\n",
    "  \n",
    "  File.open(file, 'rb') do |f|\n",
    "    begin\n",
    "      while !f.eof?\n",
    "        yield Marshal.load(f)\n",
    "      end\n",
    "    rescue EOFError\n",
    "      # Break out if we hit end of file\n",
    "    end\n",
    "  end\n",
    "end\n",
    "\n",
    "def load_embeddings(file)\n",
    "  embeddings = []\n",
    "  each_embedding(file) do |embedding|\n",
    "    embeddings << embedding\n",
    "  end\n",
    "  embeddings\n",
    "end\n",
    "\n",
    "def save_embeddings(model, texts, prefix: \"passage: \", cache_file: \"embeddings.cache\", batch_size: 100)\n",
    "  texts = [texts] unless texts.is_a?(Array)\n",
    "  \n",
    "  # Figure out how many embeddings are already in the cache\n",
    "  start_idx = each_embedding(cache_file).count rescue 0\n",
    "  \n",
    "  # Slice the texts in sets of N (e.g., 100)\n",
    "  total = texts.length\n",
    "  texts[start_idx..].each_slice(batch_size).with_index do |batch, batch_idx|\n",
    "    # Apply the prefix to each text in the batch\n",
    "    prefixed_batch = batch.map { |t| \"#{prefix}#{t}\" }\n",
    "    \n",
    "    # Get embeddings for the entire batch at once (if your model supports batch calls)\n",
    "    embeddings = model.(prefixed_batch)\n",
    "    \n",
    "    # Save each embedding\n",
    "    embeddings.each do |embedding|\n",
    "      save_embedding(embedding, cache_file)\n",
    "    end\n",
    "    \n",
    "    # Progress indicator\n",
    "    current = start_idx + batch_idx * batch_size + batch.size\n",
    "    percent = (current.to_f / total * 100).to_i\n",
    "    print \"\\rProcessing embeddings: #{percent}% (#{current}/#{total})\"\n",
    "  end\n",
    "  \n",
    "  print \"\\nDone!\\n\"\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef82fae-9ef6-454b-bd25-ddfee614e34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will take about 24 hours on Mac M1 due to docker/virtualization issues!  Takes 5 minutes when not in Docker\n",
    "#save_embeddings(model,title_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafd559d-2822-4758-993b-fa2a8c160ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Embeddings for 50_000 titles is about 500MB cached - make sure you have enough docker RAM\n",
    "$title_embeddings = load_embeddings(\"embeddings.cache\")\n",
    "$title_embeddings.first(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa4dc29-9902-4912-b4cb-4c7f5cb46907",
   "metadata": {},
   "outputs": [],
   "source": [
    "require 'objspace'\n",
    "\n",
    "puts ObjectSpace.memsize_of($title_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29639222-d1f2-4465-a212-cd64f4205c41",
   "metadata": {},
   "source": [
    "### brute-force nearest neighbor calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8793df-0b72-4115-995c-0be7b1d05f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "$dataset = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393113fa-e96b-49f6-b73d-80a3abdeea1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "$title_tensor = Torch.tensor($title_embeddings)\n",
    "def cosine_similarity(query_embedding)\n",
    "    cos = Torch::NN::CosineSimilarity.new(dim: 1, eps: 1e-6)\n",
    "\n",
    "    # Convert arrays to tensors and reshape them\n",
    "    query_tensor = Torch.tensor(query_embedding)\n",
    "\n",
    "    # Calculate cosine similarity\n",
    "    similarity = cos.call(query_tensor, $title_tensor)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a7324e-885c-4b86-b65a-ea8bf415d23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(query,model, k: 5)\n",
    "    query_embedding = get_embeddings(model, query, prefix: \"query: \")\n",
    "    puts \"query_embedding 1st number: #{query_embedding[0][0]}\"\n",
    "    puts \"title_embeddings 1st number: #{$title_embeddings[0][0]}\"\n",
    "    \n",
    "    #Score the relation between the query embedding and all title embeddings\n",
    "    start_time = Time.now\n",
    "    cosine_scores = cosine_similarity(query_embedding).flatten.to_a\n",
    "    scores_series = Polars::Series.new(\"scores\", cosine_scores)\n",
    "    \n",
    "    # Reverse sort (descending will yield the nearest neighbors on top:\n",
    "    sorted_indices = scores_series.arg_sort(reverse: true).to_a\n",
    "    top_k_indices = sorted_indices.first(k)  # Using k instead of hardcoded 5\n",
    "    \n",
    "    #How long did it take?\n",
    "    end_time = Time.now\n",
    "    elapsed_time = (end_time - start_time) * 1000.0\n",
    "    \n",
    "    #Print out the top K titles and the scores\n",
    "    most_similar = top_k_indices.map { |i| \"#{cosine_scores[i]} | #{$dataset['title'][i]}\" }\n",
    "    most_similar.each do |string|\n",
    "      puts string\n",
    "    end\n",
    "    puts \"Took: #{elapsed_time.round(2)} ms\" \n",
    "    nil\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8714b6d5-65f5-4194-802e-1bbc7f1a8014",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn(\"housing market\",model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d944a61-a028-49df-b2a6-79e4acfa7be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn(\"property market\",model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb45dd4-15b5-4447-b0b9-8c83daad7af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn(\"ballet dancing changes\",model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560b7532-7075-421d-b6bc-0e30d9a836f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn(\"climate change\",model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819d1a30-37d1-4d3e-903b-fe981d9673eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn(\"global warming in the united states\",model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b6ba21-df56-4821-ab26-f9db96e0639f",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn(\"taylor swift\",model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Ruby 3.1.3",
   "language": "ruby",
   "name": "ruby"
  },
  "language_info": {
   "file_extension": ".rb",
   "mimetype": "application/x-ruby",
   "name": "ruby",
   "version": "3.1.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
