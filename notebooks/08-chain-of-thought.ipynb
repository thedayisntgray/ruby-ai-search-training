{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3d8ce0f-bcdb-43fe-b20e-e6ef4c0534c2",
   "metadata": {},
   "source": [
    "# Lab 8 - Chain-of-Thought OpenAI GPT-4o-mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b42562-c0ad-4c2d-8673-1a71f67bec63",
   "metadata": {},
   "outputs": [],
   "source": [
    "require 'json'\n",
    "require 'ruby-openai'\n",
    "require 'dotenv'\n",
    "\n",
    "# Load environment variables from .env file\n",
    "Dotenv.load\n",
    "\n",
    "# Don't include keys like this, use ENV vars!\n",
    "config = JSON.parse(File.read('config.json'))\n",
    "client = OpenAI::Client.new(access_token: config['openai_key'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6117b0-58f6-4091-b78e-22959239ff99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete(prompt)\n",
    "  response = client.chat(\n",
    "    parameters: {\n",
    "      model: \"gpt-4o-mini\",\n",
    "      messages: [{ role: \"user\", content: prompt }],\n",
    "      temperature: 0\n",
    "    }\n",
    "  )\n",
    "\n",
    "  response.dig(\"choices\", 0, \"message\", \"content\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46b8d5b-64e6-4d92-8a9a-af5c1ff81c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_steps_prompt(query)\n",
    "  \"#{query}\\n\\nBefore answering, think step-by-step.\"\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f5c97b-3df3-4a0c-a63e-e242b795a476",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer_prompt(query, steps)\n",
    "  \"#{query}\\n\\n#{steps}\\n\\nANSWER:\"\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245ffde9-46ce-424f-9f48-04d937e8d5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer(query)\n",
    "  # Get the first prompt, including the step-by-step instruction\n",
    "  prompt_1 = get_steps_prompt(query)\n",
    "  \n",
    "  # We get the chain-of-thought steps response back from GPT\n",
    "  puts \"Thinking...\"\n",
    "  steps = complete(prompt_1)\n",
    "  puts \"Steps generated\"\n",
    "  \n",
    "  # Get the answer portion of the chain-of-thought-prompt\n",
    "  puts \"Thinking...\"\n",
    "  prompt_2 = get_answer_prompt(query, steps)\n",
    "  puts \"Answer extracted\"\n",
    "\n",
    "  response = complete(prompt_2)\n",
    "  puts response\n",
    "  \n",
    "  response\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c57f9f-4819-4958-8634-c15fa0bb5520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask a question\n",
    "answer(\"Alice and Bob go to a hotel with 255 rooms. Bob sleeps in one of the rooms and Alice sleeps in another. How many vacant rooms are available?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62185672-80d6-46c8-9a82-b69638119490",
   "metadata": {},
   "source": [
    "## Using OpenAI structured output for a single-request Chain-of-Thought answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f687a15-a204-41a7-8b99-358f0121cb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_chain_of_thought(name, prompt)\n",
    "  puts \"Thinking...\"\n",
    "  \n",
    "  schema = {\n",
    "    name: name,\n",
    "    strict: true,\n",
    "    schema: {\n",
    "      type: \"object\",\n",
    "      properties: {\n",
    "        steps: {\n",
    "          type: \"array\",\n",
    "          items: {\n",
    "            type: \"object\",\n",
    "            properties: {\n",
    "              explanation: { type: \"string\" },\n",
    "              output: { type: \"string\" }\n",
    "            },\n",
    "            required: [\"explanation\", \"output\"],\n",
    "            additionalProperties: false\n",
    "          }\n",
    "        },\n",
    "        final_answer: { type: \"string\" }\n",
    "      },\n",
    "      required: [\"steps\", \"final_answer\"],\n",
    "      additionalProperties: false\n",
    "    }\n",
    "  }\n",
    "\n",
    "  response = client.chat(\n",
    "    parameters: {\n",
    "      model: \"gpt-4o-mini\",\n",
    "      messages: [\n",
    "        {\n",
    "          role: \"system\",\n",
    "          content: \"You are a helpful assistant. Always analyze and think step-by-step before responding with the final answer.\"\n",
    "        },\n",
    "        {\n",
    "          role: \"user\",\n",
    "          content: prompt\n",
    "        }\n",
    "      ],\n",
    "      temperature: 0,\n",
    "      response_format: {\n",
    "        type: \"json_schema\",\n",
    "        json_schema: schema\n",
    "      }\n",
    "    }\n",
    "  )\n",
    "\n",
    "  begin\n",
    "    content = response.dig(\"choices\", 0, \"message\", \"content\")\n",
    "    content_json = JSON.parse(content)\n",
    "    steps = content_json[\"steps\"]\n",
    "    final_answer = content_json[\"final_answer\"]\n",
    "    \n",
    "    puts \"Steps:\"\n",
    "    puts steps\n",
    "    puts \"Final Answer:\"\n",
    "    puts final_answer\n",
    "    \n",
    "    final_answer\n",
    "  rescue StandardError => e\n",
    "    puts response\n",
    "    puts e.message\n",
    "    nil\n",
    "  end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec8c840-78f3-4a77-8eef-89e49ee32bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask a question\n",
    "answer_chain_of_thought(\"vacancy_calculator\", \"Alice and Bob go to a hotel with 255 rooms. Bob sleeps in one of the rooms and Alice sleeps in another. How many vacant rooms are available?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Ruby 3.1.3",
   "language": "ruby",
   "name": "ruby"
  },
  "language_info": {
   "file_extension": ".rb",
   "mimetype": "application/x-ruby",
   "name": "ruby",
   "version": "3.1.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
